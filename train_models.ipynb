{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf7b25c7",
   "metadata": {},
   "source": [
    "This notebook is to train and store models to disc.\\\n",
    "This Notebook has to be clean (do not define functions here, do them in an\n",
    "external utils.py and import them).\\\n",
    "This notebook has to be reproducible (if you run it twice, the same output has to\n",
    "be displayed and stored to disk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f8a305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and set randome seed for reproducibility\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "from sklearn import *\n",
    "import os\n",
    "import pickle # to save model\n",
    "from utils import *\n",
    "RANDOM_SEED = 123 # taken from task description\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39568d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to train and VALIDATE your solution\n",
    "train_df = pd.read_csv(\"./quora_train_data.csv\")\n",
    "\n",
    "# use this to provide the expected generalization results\n",
    "test_df = pd.read_csv(\"./quora_test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8784dd",
   "metadata": {},
   "source": [
    "We need to convert our questions to strings in order to work with CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3309e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((323432, 156550), (323432, 6), (80858, 156550), (80858, 6))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract questions (documents) and cast to strings\n",
    "q1_train =  cast_list_as_strings(list(train_df[\"question1\"]))\n",
    "q2_train =  cast_list_as_strings(list(train_df[\"question2\"]))\n",
    "all_questions = q1_train + q2_train\n",
    "\n",
    "# fit on train set\n",
    "count_vectorizer_v1 = sklearn.feature_extraction.text.CountVectorizer(ngram_range=(1,1))\n",
    "count_vectorizer_v1.fit(all_questions)\n",
    "\n",
    "X_tr_q1q2 = get_features_from_df(train_df,count_vectorizer_v1)\n",
    "X_te_q1q2  = get_features_from_df(test_df, count_vectorizer_v1)\n",
    "\n",
    "X_tr_q1q2.shape, train_df.shape, X_te_q1q2.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717056e0",
   "metadata": {},
   "source": [
    "Divide processed train set into train and validation according to task description split. Using `random_seed = 123`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06b65da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_df.shape= (307260, 156550)\n",
      "va_df.shape= (16172, 156550)\n",
      "te_df.shape= (80858, 156550)\n",
      "y_train.shape= (307260,)\n",
      "y_val.shape= (16172,)\n"
     ]
    }
   ],
   "source": [
    "# divide into train and validation set\n",
    "tr_df, va_df, y_train, y_val = sklearn.model_selection.train_test_split(X_tr_q1q2, train_df[\"is_duplicate\"].values, test_size=0.05, random_state=RANDOM_SEED)\n",
    "print('tr_df.shape=',tr_df.shape)\n",
    "print('va_df.shape=',va_df.shape)\n",
    "print('te_df.shape=',X_te_q1q2.shape)\n",
    "print('y_train.shape=',y_train.shape)\n",
    "print('y_val.shape=',y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa3f3e",
   "metadata": {},
   "source": [
    "Train model on count vectorized matrix of question1 and question2 using train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4906a409",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\",random_state=RANDOM_SEED)\n",
    "logistic.fit(tr_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "save_model(\"logreg\",logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ddde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "print(\"Validation Results\")\n",
    "predictions = logistic.predict(va_df)\n",
    "result = roc_auc_score(y_val, predictions)\n",
    "print(\"Val ROC-AUC: %.3f\"%(result))\n",
    "      \n",
    "# Test   \n",
    "print(\"\\nTest Results\")\n",
    "predictions = logistic.predict(X_te_q1q2)\n",
    "result = roc_auc_score(test_df[\"is_duplicate\"].values, predictions)\n",
    "print(\"Test ROC-AUC: %.3f\"%(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28067f93",
   "metadata": {},
   "source": [
    "### Improved version using cosine similiarity and preprocessing\n",
    "Our manually written preprocess function is very inefficient and takes quite long to run, instead we use CountVectorizer with similar hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a4edc07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import preprocess # own preprocess function takes to long\n",
    "# divide into train and validation set\n",
    "\n",
    "SUBSET = 30000\n",
    "tr_df, va_df, y_train, y_val = sklearn.model_selection.train_test_split(train_df, train_df[\"is_duplicate\"].values, test_size=0.05, random_state=RANDOM_SEED)\n",
    "q1_train =  tr_df[\"question1\"].fillna(' ')[:SUBSET]\n",
    "q2_train =  tr_df[\"question2\"].fillna(' ')[:SUBSET]\n",
    "q1_val =  va_df[\"question1\"][:SUBSET]\n",
    "q2_val =  va_df[\"question2\"][:SUBSET]\n",
    "q1_test =  test_df[\"question1\"][:SUBSET]\n",
    "q2_test =  test_df[\"question2\"][:SUBSET]\n",
    "all_questions = q1_train + q2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a0783ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# count_vectorizer = CountVectorizer(ngram_range=(1,1),lowercase=True,tokenizer=tokenize)\n",
    "count_vectorizer = CountVectorizer(ngram_range=(1,1),lowercase=True,stop_words='english')\n",
    "sparse_matrix = count_vectorizer.fit(all_questions) # vocabulary\n",
    "q1 = count_vectorizer.transform(q1_train)\n",
    "q2 = count_vectorizer.transform(q2_train)\n",
    "result = cosine_similarity(q1,q2).diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b3fd959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results\n",
      "Train ROC-AUC: 0.676\n"
     ]
    }
   ],
   "source": [
    "# Train Set Performance\n",
    "print(\"Train Results\")\n",
    "predictions = np.where(result > 0.5,1,0)\n",
    "result = roc_auc_score(y_train[:SUBSET], predictions)\n",
    "print(\"Train ROC-AUC: %.3f\"%(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe26b7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Val ROC-AUC: 0.680\n",
      "\n",
      "Test Results\n",
      "Test ROC-AUC: 0.683\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "print(\"Validation Results\")\n",
    "q1 = count_vectorizer.transform(q1_val)\n",
    "q2 = count_vectorizer.transform(q2_val)\n",
    "result = cosine_similarity(q1,q2).diagonal()\n",
    "predictions = np.where(result > 0.5,1,0)\n",
    "result = roc_auc_score(y_val[:SUBSET], predictions)\n",
    "print(\"Val ROC-AUC: %.3f\"%(result))\n",
    "      \n",
    "# Test   \n",
    "print(\"\\nTest Results\")\n",
    "q1 = count_vectorizer.transform(q1_test)\n",
    "q2 = count_vectorizer.transform(q2_test)\n",
    "result = cosine_similarity(q1,q2).diagonal()\n",
    "predictions = np.where(result > 0.5,1,0)\n",
    "result = roc_auc_score(test_df[\"is_duplicate\"].values[:SUBSET], predictions)\n",
    "print(\"Test ROC-AUC: %.3f\"%(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e27b7b8",
   "metadata": {},
   "source": [
    "Use TD-IDF to compute feature vectors and cosine similiarity to compute if questions are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "369f5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer # can reuse wordcount from previous cells\n",
    "transformer = TfidfTransformer(use_idf=True) # use_idf needs to be set to true for td-idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528b7dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
