{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf7b25c7",
   "metadata": {},
   "source": [
    "This notebook is to train and store models to disc.\\\n",
    "This Notebook has to be clean (do not define functions here, do them in an\n",
    "external utils.py and import them).\\\n",
    "This notebook has to be reproducible (if you run it twice, the same output has to\n",
    "be displayed and stored to disk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0f8a305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and set randome seed for reproducibility\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "from sklearn import *\n",
    "import os\n",
    "import pickle # to save model\n",
    "from utils import *\n",
    "RANDOM_SEED = 123 # taken from task description\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717056e0",
   "metadata": {},
   "source": [
    "Divide processed train set into train and validation according to task description split. Using `random_seed = 123`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39568d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_df.shape= (291897, 6)\n",
      "va_df.shape= (15363, 6)\n",
      "te_df.shape= (16172, 6)\n"
     ]
    }
   ],
   "source": [
    "# use this to train and VALIDATE your solution\n",
    "data = pd.read_csv(\"./quora_train_data.csv\")\n",
    "\n",
    "# this split is to create same splits across teams\n",
    "A_df, test_df, y_A, y_test = train_test_split(data, data[\"is_duplicate\"].values, test_size=0.05, random_state=RANDOM_SEED)\n",
    "train_df, va_df, y_train, y_val = train_test_split(A_df,y_A, test_size=0.05, random_state=RANDOM_SEED)\n",
    "\n",
    "print('tr_df.shape=',train_df.shape) # tr_df.shape= (307260, 156550)\n",
    "print('va_df.shape=',va_df.shape) # va_df.shape= (16172, 156550)\n",
    "print('te_df.shape=',test_df.shape) # te_df.shape= (80858, 156550)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8784dd",
   "metadata": {},
   "source": [
    "We need to convert our questions to strings in order to work with CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3309e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((291897, 149650), (291897, 6), (15363, 149650), (15363, 6))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract questions (documents) and cast to strings\n",
    "q1_train =  cast_list_as_strings(list(train_df[\"question1\"]))\n",
    "q2_train =  cast_list_as_strings(list(train_df[\"question2\"]))\n",
    "all_questions = q1_train + q2_train\n",
    "\n",
    "# fit on train set\n",
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer()\n",
    "count_vectorizer.fit(all_questions)\n",
    "\n",
    "X_tr_q1q2 = get_features_from_df(train_df, count_vectorizer)\n",
    "X_va_q1q2  = get_features_from_df(va_df, count_vectorizer)\n",
    "\n",
    "X_tr_q1q2.shape, train_df.shape, X_va_q1q2.shape, va_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa3f3e",
   "metadata": {},
   "source": [
    "Train model on count vectorized matrix of question1 and question2 using train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4906a409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=123, solver='liblinear')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = sklearn.linear_model.LogisticRegression(solver=\"liblinear\",random_state=RANDOM_SEED)\n",
    "logistic.fit(X_tr_q1q2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cca3ffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "with open(\"logreg.sav\", 'wb') as fout:\n",
    "    pickle.dump((count_vectorizer, logistic), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b77ddde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Val ROC-AUC: 0.720\n",
      "\n",
      "Test Results\n",
      "Test ROC-AUC: 0.729\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "print(\"Validation Results\")\n",
    "va_df_prep = get_features_from_df(va_df,count_vectorizer)\n",
    "predictions = logistic.predict(va_df_prep)\n",
    "result = roc_auc_score(y_val, predictions)\n",
    "print(\"Val ROC-AUC: %.3f\"%(result))\n",
    "      \n",
    "# Test   \n",
    "print(\"\\nTest Results\")\n",
    "te_df_prep = get_features_from_df(test_df,count_vectorizer)\n",
    "predictions = logistic.predict(te_df_prep)\n",
    "result = roc_auc_score(test_df[\"is_duplicate\"].values, predictions)\n",
    "print(\"Test ROC-AUC: %.3f\"%(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28067f93",
   "metadata": {},
   "source": [
    "### Improved version using cosine similiarity and preprocessing\n",
    "Our manually written preprocess function is very inefficient and takes quite long to run, instead we use CountVectorizer with similar hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a4edc07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291897,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import preprocess # own preprocess function takes to long\n",
    "\n",
    "q1_train =  train_df[\"question1\"].fillna(' ')\n",
    "q2_train =  train_df[\"question2\"].fillna(' ')\n",
    "q1_val =  va_df[\"question1\"]\n",
    "q2_val =  va_df[\"question2\"]\n",
    "q1_test =  test_df[\"question1\"]\n",
    "q2_test =  test_df[\"question2\"]\n",
    "all_questions = q1_train + q2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a0783ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count_vectorizer = CountVectorizer(tokenizer=tokenize) # with stemming\n",
    "# sparse_matrix = count_vectorizer.fit(all_questions) # vocabulary\n",
    "q1 = count_vectorizer.transform(q1_train)\n",
    "q2 = count_vectorizer.transform(q2_train)\n",
    "# result = cosine_similarity(q1,q2).diagonal() # takes to much memory for big matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fc09358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "result = []\n",
    "for i in range(q1.shape[0]): # for loop to avoid running out of memory\n",
    "    result.append(cosine_similarity(q1[i],q2[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43ba246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [item for sub_list in result for item in sub_list]\n",
    "result = [item for sub_list in result for item in sub_list] # needs to be done 2 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91238e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe as a csv file\n",
    "pd.DataFrame(result).to_csv(\"train_cosine_similiarity.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b3fd959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results\n",
      "Train ROC-AUC: 0.672\n"
     ]
    }
   ],
   "source": [
    "# Train Set Performance\n",
    "print(\"Train Results\")\n",
    "predictions = np.where(np.asarray(result) > 0.5,1,0)\n",
    "# result = roc_auc_score(y_train[:SUBSET], predictions)\n",
    "result = roc_auc_score(y_train, predictions)\n",
    "print(\"Train ROC-AUC: %.3f\"%(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe26b7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Val ROC-AUC: 0.669\n",
      "\n",
      "Test Results\n",
      "Test ROC-AUC: 0.668\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "print(\"Validation Results\")\n",
    "q1 = count_vectorizer.transform(q1_val)\n",
    "q2 = count_vectorizer.transform(q2_val)\n",
    "result = get_cosine_sim(q1,q2)\n",
    "pd.DataFrame(result).to_csv(\"val_cosine_similiarity.csv\",index=False)\n",
    "predictions = np.where(result > 0.5,1,0)\n",
    "result = roc_auc_score(y_val, predictions)\n",
    "print(\"Val ROC-AUC: %.3f\"%(result))\n",
    "      \n",
    "# Test   \n",
    "print(\"\\nTest Results\")\n",
    "q1 = count_vectorizer.transform(q1_test)\n",
    "q2 = count_vectorizer.transform(q2_test)\n",
    "result = get_cosine_sim(q1,q2)\n",
    "pd.DataFrame(result).to_csv(\"test_cosine_similiarity.csv\",index=False)\n",
    "predictions = np.where(result > 0.5,1,0)\n",
    "result = roc_auc_score(test_df[\"is_duplicate\"].values, predictions)\n",
    "print(\"Test ROC-AUC: %.3f\"%(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e27b7b8",
   "metadata": {},
   "source": [
    "Use TD-IDF to compute feature vectors and cosine similiarity to compute if questions are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "369f5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer # can reuse wordcount from previous cells\n",
    "tfidf_transformer = TfidfTransformer(use_idf=True) # use_idf needs to be set to true for td-idf\n",
    "word_count = count_vectorizer.transform(all_questions)\n",
    "tfidf = tfidf_transformer.fit_transform(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb4119be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                TF-IDF\n",
      "backend       0.550495\n",
      "java          0.379052\n",
      "or            0.297714\n",
      "gui           0.293719\n",
      "amongst       0.289712\n",
      "startups      0.222999\n",
      "develop       0.201415\n",
      "popular       0.192509\n",
      "development   0.189478\n",
      "software      0.173458\n",
      "language      0.165008\n",
      "most          0.127981\n",
      "will          0.113445\n",
      "have          0.102124\n",
      "which         0.101078\n",
      "for           0.078056\n",
      "and           0.072000\n",
      "do            0.064819\n",
      "how           0.058484\n",
      "is            0.052148\n",
      "the           0.048485\n",
      "peacemaker    0.000000\n",
      "peacekeeping  0.000000\n",
      "peach         0.000000\n",
      "peacekeepers  0.000000\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(tfidf[0].T.todense(), index=count_vectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print (df.head(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7c9142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "q1_mat = tfidf_transformer.transform(count_vectorizer.transform(q1_train))\n",
    "q2_mat = tfidf_transformer.transform(count_vectorizer.transform(q2_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a971326",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf_cos = get_cosine_sim(q1_mat, q2_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd5b540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe as a csv file\n",
    "pd.DataFrame(train_tfidf_cos).to_csv(\"train_tfidf_cos.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ce64929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Results\n",
      "Train ROC-AUC: 0.675\n"
     ]
    }
   ],
   "source": [
    "# Train Set Performance\n",
    "print(\"Train Results\")\n",
    "predictions = np.where(train_tfidf_cos > 0.5,1,0)\n",
    "result = roc_auc_score(y_train, predictions)\n",
    "print(\"Train ROC-AUC: %.3f\"%(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45759c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results\n",
      "Val ROC-AUC: 0.666\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "print(\"Validation Results\")\n",
    "q1 = tfidf_transformer.transform(count_vectorizer.transform(q1_val))\n",
    "q2 = tfidf_transformer.transform(count_vectorizer.transform(q2_val))\n",
    "val_result = get_cosine_sim(q1, q2)\n",
    "pd.DataFrame(val_result).to_csv(\"val_tfidf_cos.csv\",index=False)\n",
    "predictions = np.where(val_result > 0.5,1,0)\n",
    "result = roc_auc_score(y_val, predictions)\n",
    "print(\"Val ROC-AUC: %.3f\"%(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc8ca62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results\n",
      "Test ROC-AUC: 0.669\n"
     ]
    }
   ],
   "source": [
    "# Test   \n",
    "print(\"\\nTest Results\")\n",
    "q1 = tfidf_transformer.transform(count_vectorizer.transform(q1_test))\n",
    "q2 = tfidf_transformer.transform(count_vectorizer.transform(q2_test))\n",
    "test_result = cosine_similarity(q1,q2).diagonal()\n",
    "pd.DataFrame(test_result).to_csv(\"test_tfidf_cos.csv\",index=False)\n",
    "predictions = np.where(test_result > 0.5,1,0)\n",
    "result = roc_auc_score(test_df[\"is_duplicate\"], predictions)\n",
    "print(\"Test ROC-AUC: %.3f\"%(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2fcb83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
